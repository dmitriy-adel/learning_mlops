# Теория по Docker и Kubernetes

- Здесь будет собрана теория в текстовом виде ради увеличения скорости ее запоминания и возможность подглядеть при необходимости. Посколкьу в этот раз у меня нет референса в качестве уроков, я постараюсь реализовать свою идею по организации информации

## Термины

### Container

- `Container` — это изолированный процесс, запускающий компоненты приложения (например, фронтенд, бэкенд, базу данных) в собственной среде, отдельной от остального окружения системы, что позволяет избежать конфликтов с уже установленным ПО на хосте и обеспечивает следующие преимущества:

    - Самодостаточность: контейнер содержит всё необходимое для работы — зависимости, библиотеки, конфигурации. Не нужно ничего устанавливать на хост — приложение работает автономно буквально из коробки

    - Изоляция: контейнер минимально влияет на хост и другие контейнеры, что повышает безопасность и предсказуемость всей структуры

    - Независимость: каждый контейнер управляется отдельно — удаление одного не затрагивает другие

    - Портативность: контейнер, запущенный на одной локальной машине, будет работать точно так же в дата-центре или в облаке. 

### Image

- `Image` - это стандартизированный пакет, который включает в себя все необходимые файлы, бинарники, библиотеки и конфигурации для запуска контейнера. Например, PostgreSQL-образ содержит двоичные файлы базы данных, конфигурационные файлы и зависимости; для веб-приложения на Python — среду выполнения Python, код приложения и все зависимости

- Ключевые принципы образов: 

    - `Неизменяемость (immutable)`. После создания образа его нельзя изменить. Вместо этого создается новый образ и происходит добавление изменений поверх существующего образа

    - `Состоит из слоёв (layers)`. Образы состоят из нескольких слоёв. Каждый слой представляет собой набор изменений файловой системы: добавление, модификация или удаление файлов, что позволяет расширять существующие образы, например, начать с образа python и добавить слои, устанавливая зависимости и загружая код приложения

- Разница контейнеров и образов: 

    - Контейнер — это запущенный экземпляр образа. Образы — статичные, неизменяемые шаблоны, а контейнеры — динамичные экземпляры, которые создаются на основе этих образов. При запуске контейнера Docker добавляет записывающий слой поверх образа, позволяя изменить его поведение во время выполнения

### Registry

- `Image registry` — это централизованное место для хранения и обмена контейнерными образами. Он может быть как публичным, так и приватным. Docker Hub — это публичный реестр по умолчанию, доступный всем

- Разница реестра и репозитория: 

    - Registry (реестр) — это сервер или сервис, который управляет хранением и доступом к контейнерным образам

    - Repository (репозиторий) — это логическая коллекция образов внутри реестра, объединённых общей темой (например, проектом или приложением). Каждый репозиторий содержит различные версии образов, отличающиеся тегами

- Типы реестров: 

    - Публичные (Public registries). Открытые реестры, доступные любому пользователю. Docker Hub — самый известный пример

    - Частные (Private registries). Реестры с ограниченным доступом, часто используемые внутри компании или организации. Их можно развернуть локально или использовать облачные решения

    - Облачные сервисы. Поставщики облаков предлагают собственные реестры:

        1. Amazon ECR (Elastic Container Registry)

        2. Azure Container Registry (ACR)

        3. Google Container Registry (GCR)

        Кроме того, существуют решения вроде Harbor, JFrog Artifactory/Container Registry, GitLab Registry — как для самохостинга, так и в облаке

### Docker Network

- Docker Network — это система обеспечения сетевой связи контейнеров между собой и с другими, внешними сервисами. Каждый контейнер получает сетевой интерфейс, IP-адрес, шлюз, маршруты, DNS и др., если не используется драйвер none, полностью изолирующий контейнер. Docker Network в основном применяется для: 

    - Связывание контейнеров между собой на одном хосте или между разными хостами
    - Изоляция или распространение сетевого трафика
    - Контроль доступа к сетевым ресурсам
    - Настраиваемость, масштабируемость и гибкость сетевых топологий

- Docker по умолчанию поддерживает несколько встроенных сетевых драйверов:

    1. `bridge` — стандартная внутренняя сеть по умолчанию

    2. `host` — убирает сетевую изоляцию контейнера, предоставляя ему сетевой стек хоста

    3. `none` — отключённая сеть, контейнер без сетевого доступа

    4. `overlay` — нескольким Docker-демонам (чаще — хостам) обеспечивает общую сеть

    5. `ipvlan` — полный контроль над IPv4 и IPv6 адресацией

    6. `macvlan` — назначение уникального MAC-адреса каждому контейнеру

    Также есть возможность создать пользовательскую сеть при помощи команды `docker network`. Например, команда

    ```bash
    docker network create -d bridge my-net
    ```

    создаст сеть с именем *my-net* типа *bridge*. На bridge-сети по умолчанию порты контейнера не доступны снаружи. Чтобы открыть доступ — используется `-p` или `--publish`, что создаёт правило на хосте, перенаправляющее порт хоста на порт контейнера. Можно ограничить доступ только локальным хостом, указав *127.0.0.1:hostPort:containerPort;* важно помнить, что публикация без ограничений потенциально небезопасна

- Контейнер может подключаться сразу к нескольким сетям (например, одному мосту и внутренней сети). В таком случае он выбирает шлюз в зависимости от приоритетов — при помощи параметра gw-priority, чтобы определить, какая сеть станет шлюзом по умолчанию

- По умолчанию контейнер получает IP-адрес из подсети сети (IPv4 активирована, IPv6 можно включить флагом *--ipv6*). Можно задать конкретный IP через *--ip*/*--ip6* либо установить собственный hostname через *--hostname* или *--alias* при подключении

### Docker Compose

- Docker Compose - тулза, которая позволяет проще управлять оркестром контейнеров. с ней проще запускать взаимосвязанные сервисы (анпример, бэк и фронт одного приложения), 9все инструкции прописываются в .yml конфиге. он позволяет описывать весь стек — сервисы, сети, тома — и запускать всё одним командным вызовом, например, docker compose up 

---

## Команды

- `docker run` - команда для запуска контейнера из образа. напрмиер,

    ```
    sudo docker run nginx
    ```

    запустит экземпляр приложения *nginx* на хосте, если образ есть локально. если образа нет на хосте, докер пойдет на *docker hub* и спулит его. например, bash-скрипт
    
    ```bash
    #!/bin/bash

    sudo docker run misaogura/whalesay "Whalesay for ur name! $1"

    exit
    ``` 
    
    запустит экземпляр контейнера *whalesay* из репозитория *misaogura* с именем, равным первому переданному аргументу
    
    чтобы запустить контейнер с определенной версией приложения, необходимо использовать тэги. например, 
    
    ```bash
    #!/bin/bash

    sudo docker run -it nginx:1.29
    
    exit
    ```
    запустит контейнер с *nginx* версии *1.29*, если такая есть (1.29 - тэг). флаги *-it* (t - терминал, i - интерактив) позволяют запускать контейнеры в интерактивном режиме и связывать свой терминал с терминалом контейнера

    - `--link` - флаг для указания связи между контейнерами. грубо говоря, контейнер узнает о существовании другого контейнера, позволяя им взаимодействовать между друг другом, но это несколько устаревший вариант

- `docker ps` - команда покажет запущенные контейнеры
    - чтобы увидеть все спуленные контейнеры, надо использовать флаг **-a**
    - флаг **-q** переключает вывод в 'тихий' режим, который показывает только id контейнеров
    - флаг **-f** предоставляет возможности фильтра. фильтровать вывод можно по метаданным контейнера (о них более подробно рассказано в docker inspect)

- `docker stop` - команда, используемая для остановки контейнера по его *CONTAINER ID*. для остановки всех доступных контейнеров стоит использовать скрипт: 

    ```bash
    #!/bin/bash

    sudo docker stop $(sudo docker ps -q)
    exit
    ```

- `docker rm` - удаление остановленного или заврешнного контейнера по имени или id. ниже приведен пример использования *docker rm* для удалениях всех остановленных контейнеров, кроме последних 3-х, отсортированных по времени создания

    ```bash
    #!/bin/bash

    sduo docker rm $(sudo docker ps -a -q -f status=exited | tail -n +4)

    exit
    ```

- `docker images` - покажет все образы, установленные локально. каждый контейнер привязан к собственному образу, поэтому нельзя удалить образ, не удалив все контейнеры от него

- `docker rmi` - команда для удаления образов по имени или по id. образ можно удалить только в том случае, если на него больше не ссылаются контейнеры 

- `docker pull` - команда для скачивания образов с хаба. чтобы спулить определенную версию, надо использовать тэги (:(tag)vers.ion)

- `docker inspect` - вывод полной информации по контейнеру 

- `docker logs` - просмотр логов контейнера. что интересно, если стопнуть контейнер, и после этого запросить его логи, логи все равно будут выведены

- `docker history` - информация о слоях контейнера

- `docker build` - команда для построения контейнера по *dockerfile*. например, `docker build -t "appdev:Dockerfile" .` ; построение из другой директории - `docker build . -t my-web-app -f webapp-rockets/Dockerfile`

- `docker image purne` - команда, которая удаляет все неиспользуемые контейнеры, на которые нет ссылок

---

## Идеи

- Контейнер - изолированное приложение со своими процессами, своей сетью и своим монтированием. docker контейнеры очень похожи на виртуальные машины за тем исключением, что в docker контейнерах одинаковая операционная система, в то время как на виртуалках - нет. контейнеры берут OS хоста и строятся вокруг нее, и есть пара нюансов: 

    1. Linux
        - Контейнеры используют Linux-ядро. Поэтому Linux-контейнеры можно запустить только на Linux (нельзя просто так взять и запустить их напрямую на Windows или macOS)

    2. Windows
        - Есть два типа контейнеров: 
            - Windows containers — используют Windows-ядро (могут запускать только Windows-приложения).

            - Linux containers — для их запуска Docker Desktop поднимает тонкую виртуалку (обычно на WSL2 или Hyper-V) с Linux-ядром. И уже там крутятся Linux-контейнеры.

    Т.е. получается, что да, на «голом» Windows нельзя запустить Linux-контейнеры. Но в реальности Docker Desktop решает это за счёт WSL2

- Основные отличия контейнеров и vm:

    - Ресурсы: ВМ потребляют больше памяти и дискового пространства, так как каждая из них содержит целую ОС. Контейнеры легче и компактнее.

    - Скорость: Контейнеры запускаются быстрее, чем ВМ.

    - Изоляция: ВМ изолированы жёстко (у каждой своё ядро), у контейнеров изоляция мягче, так как они делят ядро хоста.

    - Жизненный цикл: Контейнер существует, пока работает процесс внутри него. Если процесс завершается, контейнер тоже останавливается.

    - ОС внутри: В контейнер нельзя «поставить» произвольную ОС с собственным ядром. Контейнеры используют ядро хоста. Поэтому Linux-контейнеры работают только с Linux-ядром. На Windows и macOS они запускаются через виртуализацию (например, WSL2).

    Контейнеры легче и быстрее виртуальных машин, поскольку виртуальная машина эмулирует всё «железо» и запускает поверх него собственную ОС со своим ядром, а контейнер использует общее ядро хоста, но имеет собственное окружение для приложений

- вывод логов остановленного контейнера. я запустил одним из вышеупомянутых скриптов контейнер, скопировал его id, остановил запущенный контейнер, и попробовал взять у него логи - логи я увидел. и увидел, потому что: 

    1. Когда контейнер работает, его stdout и stderr перенаправляются в специальный лог-драйвер Docker (по умолчанию — json-file)

    2. Этот драйвер пишет логи в файлы на хосте (обычно в /var/lib/docker/containers/<container_id>/<container_id>-json.log)

    3. Когда контейнер останавливается, Docker не удаляет эти файлы — они остаются доступны для docker logs

    4. Логи контейнера исчезнут только в том случае, если его удалить при помощи команды docker rm

---

## Dockerfile

- `Dockerfile` - текстовый документ, который используется для создания образов. Он содержит инструкции для image builder, в которые входят команды для запуска, файлы, с которыми будет производиться взаимодействие, и много другого. Ниже приведен пример простого *dockerfile*, который запускает абстрактный скрипт на python: 

    ```dockerfile
    FROM python:3.12
    WORKDIR /usr/local/app

    COPY requirements.txt ./
    RUN pip install --no-cache-dir -r requirements.txt

    COPY src ./src
    EXPOSE 5000

    RUN useradd app
    USER app

    CMD ["uvicorn", "app.main:app", "--host", "0.0.0.0", "--port", "8080"]
    ```

    построчный порядок действий таков: сначала происходит пул обраща python с версией 3.12, после назначется рабочая директория контейнера - **/usr/local/app**. далее идет копирование **requirements** скрипта в раочую директорию с их установкой. после копируются все файлы из директории src в директорию src контейнера, а также документируется порт под номером **8080** (документация порта не занимает порт, а всего лишь отражает в метаданных контейнера, что контейнер слушает этот порт). после происходит запуск команды, что создает пользователя app, переключение на пользователя app. и, наконец, запуск самого сервиса через uvicorn с соответствующими параметрами

- Команды `dockerfile` являются уникальным набором инструкций для сборки образа, которые редко или вовсе не пересекаются с cli-командами. ниже приведены основные команды dockerfile: 

    - `FROM` — указание базового образа, от которого происходит наследование

    - `WORKDIR` — рабочая директория внутри контейнера

    - `COPY / ADD` — копирование файлов с хоста внутрь образа. важно отметить, что во время выполнения этих команд в аргументах не должно присутствовать никакого изменения уровня вложенности. например, команда 

        ```dockerfile
        COPY ./../requirements.txt .
        ```

        упадет с ошибкой, в то время как, при прочих равных, команда 

        ```dockerfile
        COPY requirements.txt .
        ```

        выполнится без нареканий, поскольку данные команды не видят ничего, кроме как контекст сборки. а в контекст сборки входят текущая директория и все директории ниже, но никак не выше. при этом есть возможность укзаать другую папку для контекста сборки: 

        ```bash
        sudo docker build -t test_image -f /path/to/dockerfile /path/to/build/context
        ```

        т.е. фактически мы никак не можем заставить контекст сборки смотреть наверх, но при этом можем указать, откуда смотреть ему вниз, тем самым добраться до требуемого уровня

    - `RUN` — выполнение команды (например **RUN pip install -r requirements.txt**). важно отметить, что RUN выполняет на этапе сборки контейнера, в то время как CMD выполняется во время запуска контейнера. т.е. при запущенном контейнере не получится использовать команду RUN, в то время как при сборке не получится использовать CMD

    - `CMD` — команда по умолчанию, которая запускается при старте контейнера

    - `ENTRYPOINT` — аналог *CMD*, но более "жёсткий". *ENTRYPOINT* будет выполняться всегда, в отличие от CMD, который можно заглушить, передав аргументы при запуске контейнера. зачастую в ENTRYPOINT передаются основные команды, по типу утилиты ('uvicorn') и рабочего файла ('app.main:app'), а в CMD - 

    - `EXPOSE` — документация того, какие порты слушает контейнер. порты не занимаются, просто в документации контейнера указывается номер порта

    - `ENV` — позволяет создавать и менять переменные окружения

    - `VOLUME` — указывает место для монтирования томов

    - `USER` — указывает пользователя, под которым будет проиходить запуск команд внутри контейнера

    - `ARG` — указывает аргументы, которые передаются на этапе сборки **(docker build --build-arg)**

    - `LABEL` — создает метаданные, которые позе можно посмотреть через **docker inspect**

    - `HEALTHCHECK` — команда позволяет создать автоматическую проверку доступности контейнера раз в *n* секунд. например, скрипт

        ```dockerfile
        FROM nginx:alpine*

        HEALTHCHECK --interval=30s --timeout=5s --retries=3 \
            CMD curl -f http://localhost/ || exit 1
        ``` 

        раз в 30 секунд будет проверять, доступен ли localhost. в случае недоступности контейнер помечается как *unhealthy*

    - `ONBUILD` — отложенные инструкции для образов, которые сработают только при наследовании. при сборке напрямую команды в *ONBUILD* не будут задействованы, но они отработают в наследнике в момент его инициализации 

- Dockerfile каждой командой создает новый слой, постепенно наращивая их на базовый образ. например, в dockerfile 

    ```dockerfile
    FROM ubuntu

    RUN apt-get update 
    RUN apt-get install -y python3 python3-pip
    RUN pip3 install flask 

    COPY app.py /opt/app.py 

    ENTRYPOINT FLASK_APP=/opt/app.py falsk run --host=0.0.0.0 --port=5000
    ```

    первый слой будет весить 84мб (базовый образ ubuntu), второй слой - 20мб (обновление утилит), третий -  456мб (питон), четвертый - 4.3 мб (пакет flask), пятый <1мб (копирование абстрактного файла app.py), шестой - 0б, поскольку в нем хранятся лишь метаданные

---
